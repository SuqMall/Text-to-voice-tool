import React, { useEffect, useMemo, useRef, useState } from "react";

/**
 * All-in-One Text-to-Speech — Fixed export and improved error handling (Patch)
 * -------------------------------------------------------------------------
 * This version fixes the "Export failed" error by:
 * - Adding robust checks around getDisplayMedia and MediaRecorder
 * - Providing clear, actionable status messages to the user
 * - Ensuring proper cleanup of MediaStream tracks and recorder in all failure paths
 * - Using safe mime-type detection for MediaRecorder
 *
 * Notes for users:
 * - Tab audio capture (required for exporting the synthesized speech) is only supported
 *   in some browsers (Chrome, Edge). When the browser prompt appears, choose "This Tab"
 *   and make sure audio is enabled. If your browser doesn't support this, use a server-side
 *   TTS engine for exports.
 */

type Mode = "idle" | "speaking" | "paused" | "stopped" | "exporting";

type Piece = { kind: "text"; text: string } | { kind: "break"; ms: number };

const LS_KEY = "tts.finished.settings.v1";

function saveSettings(settings: any) {
  try { localStorage.setItem(LS_KEY, JSON.stringify(settings)); } catch (e) { /* ignore */ }
}
function loadSettings<T>(fallback: T): T {
  try {
    const raw = localStorage.getItem(LS_KEY);
    if (!raw) return fallback;
    return { ...fallback, ...JSON.parse(raw) } as T;
  } catch { return fallback; }
}

function sleep(ms: number) { return new Promise(res => setTimeout(res, ms)); }

function parseInput(input: string, ssml: boolean): Piece[] {
  if (!ssml) return [{ kind: "text", text: input }];
  const pieces: Piece[] = [];
  let remaining = input;
  const breakTag = /<break\s+time="(\d+)ms"\s*\/>/i;
  while (remaining.length > 0) {
    const m = remaining.match(breakTag);
    if (!m) { pieces.push({ kind: "text", text: remaining }); break; }
    const idx = m.index ?? 0;
    if (idx > 0) pieces.push({ kind: "text", text: remaining.slice(0, idx) });
    pieces.push({ kind: "break", ms: parseInt(m[1], 10) });
    remaining = remaining.slice(idx + m[0].length);
  }
  return pieces;
}

function chunkTextForTTS(text: string, maxChars = 5000): string[] {
  if (!text) return [];
  const clean = text.replace(/\s+/g, " ").trim();
  if (clean.length <= maxChars) return [clean];

  const parts: string[] = [];
  let cursor = 0;
  while (cursor < clean.length) {
    let end = Math.min(cursor + maxChars, clean.length);
    if (end < clean.length) {
      const sub = clean.slice(cursor, end);
      const rev = sub.lastIndexOf(".");
      const q = sub.lastIndexOf("?");
      const e = Math.max(rev, q, sub.lastIndexOf("!"));
      if (e > maxChars * 0.2) {
        end = cursor + e + 1;
      }
    }
    parts.push(clean.slice(cursor, end));
    cursor = end;
  }
  return parts;
}

export default function App() {
  const [supported, setSupported] = useState<boolean>(false);
  const [voices, setVoices] = useState<SpeechSynthesisVoice[]>([]);
  const [mode, setMode] = useState<Mode>("idle");
  const [exporting, setExporting] = useState(false);
  const [status, setStatus] = useState<string>("");
  const mediaRecorderRef = useRef<MediaRecorder | null>(null);
  const recordedChunksRef = useRef<Blob[]>([]);
  const speakingRef = useRef(false);

  const [settings, setSettings] = useState(() => loadSettings({
    title: "All‑in‑One Text-to-Speech",
    tagline: "Generate, play, and export unlimited speech — directly in your browser.",
    text: "Welcome to the patched All‑in‑One TTS demo. Paste long text (books, scripts) — it will be chunked and exported as a single audio file.",
    ssml: true,
    voiceURI: "",
    lang: "",
    rate: 1.0,
    pitch: 1.0,
    volume: 1.0,
    chunkSize: 5000,
  }));

  useEffect(() => {
    const ok = typeof window !== "undefined" && "speechSynthesis" in window && !!navigator.mediaDevices;
    setSupported(ok);
    if (!ok) return;

    function loadVoices() {
      const v = window.speechSynthesis.getVoices() || [];
      setVoices(v);
      if (!settings.voiceURI && v.length) {
        const en = v.find(vo => vo.lang?.toLowerCase().startsWith("en"));
        if (en) setSettings((s: any) => ({ ...s, voiceURI: en.voiceURI || "", lang: en.lang || s.lang }));
      }
    }

    loadVoices();
    window.speechSynthesis.onvoiceschanged = loadVoices;
  }, []);

  useEffect(() => { saveSettings(settings); }, [settings]);

  const selectedVoice = useMemo(() => voices.find(v => v.voiceURI === settings.voiceURI), [voices, settings.voiceURI]);

  async function speak(playOnly = true) {
    if (!supported) {
      setStatus('Speech synthesis not supported in this browser.');
      return;
    }
    if (!settings.text || !settings.text.trim()) {
      setStatus('Enter text to speak.');
      return;
    }

    try { window.speechSynthesis.cancel(); } catch (e) { /* ignore */ }
    setMode("speaking");
    speakingRef.current = true;
    setStatus('Playing...');

    const pieces = parseInput(settings.text, settings.ssml);
    const utteranceQueue: SpeechSynthesisUtterance[] = [];

    for (const piece of pieces) {
      if (piece.kind === "break") {
        const u = new SpeechSynthesisUtterance("");
        (u as any).__break = piece.ms;
        utteranceQueue.push(u);
      } else {
        const chunks = chunkTextForTTS(piece.text, settings.chunkSize);
        for (const ch of chunks) {
          const u = new SpeechSynthesisUtterance(ch);
          if (selectedVoice) u.voice = selectedVoice;
          if (settings.lang) u.lang = settings.lang;
          u.rate = settings.rate;
          u.pitch = settings.pitch;
          u.volume = settings.volume;
          utteranceQueue.push(u);
        }
      }
    }

    for (let i = 0; i < utteranceQueue.length; i++) {
      if (!speakingRef.current) break;
      const u = utteranceQueue[i];
      if ((u as any).__break) {
        await sleep((u as any).__break);
        continue;
      }
      await new Promise<void>((resolve) => {
        let finished = false;
        u.onend = () => { if (!finished) { finished = true; resolve(); } };
        u.onerror = (ev) => { console.error('Utterance error', ev); if (!finished) { finished = true; resolve(); } };
        try { window.speechSynthesis.speak(u); } catch (err) { console.error('speak failed', err); resolve(); }
      });
    }

    speakingRef.current = false;
    setMode("idle");
    setStatus('Finished playing.');
  }

  function pause() { try { window.speechSynthesis.pause(); setMode("paused"); setStatus('Paused.'); } catch (e) { console.warn(e); } }
  function resume() { try { window.speechSynthesis.resume(); setMode("speaking"); setStatus('Resumed.'); } catch (e) { console.warn(e); } }
  function stop() { try { speakingRef.current = false; window.speechSynthesis.cancel(); setMode("stopped"); setStatus('Stopped.'); setTimeout(() => setMode("idle"), 120); } catch (e) { console.warn(e); } }

  async function exportAudio() {
    setStatus('Preparing export...');
    if (!supported) {
      setStatus('Export not supported in this browser. Use Chrome or Edge and enable tab audio capture.');
      return;
    }
    if (!settings.text || !settings.text.trim()) {
      setStatus('Enter text to export.');
      return;
    }

    const gdm = (navigator.mediaDevices as any)?.getDisplayMedia;
    if (!gdm) {
      setStatus('Your browser does not support tab audio capture (navigator.mediaDevices.getDisplayMedia). Use Chrome/Edge.');
      return;
    }

    setMode('exporting');
    setExporting(true);

    let stream: MediaStream | null = null;

    try {
      setStatus('Requesting tab capture — when the browser prompt appears, select "This Tab" and enable audio.');
      stream = await gdm.call(navigator.mediaDevices, { video: true, audio: true });
    } catch (err) {
      console.error('getDisplayMedia failed', err);
      setStatus('Tab capture canceled or blocked. Please allow tab audio capture and try again.');
      setExporting(false);
      setMode('idle');
      return;
    }

    const audioTracks = stream.getAudioTracks();
    if (!audioTracks || audioTracks.length === 0) {
      stream.getTracks().forEach(t => t.stop());
      setStatus('Captured stream contains no audio tracks. When prompted, choose "This Tab" and make sure "Share audio" is enabled.');
      setExporting(false);
      setMode('idle');
      return;
    }

    recordedChunksRef.current = [];
    const mimeCandidates = ['audio/webm;codecs=opus', 'audio/webm', 'audio/ogg;codecs=opus'];
    let mime: string | undefined = undefined;
    try {
      for (const c of mimeCandidates) {
        if ((window as any).MediaRecorder && MediaRecorder.isTypeSupported && MediaRecorder.isTypeSupported(c)) { mime = c; break; }
      }
    } catch (e) { /* ignore */ }
    if (!mime) mime = 'audio/webm';

    let mr: MediaRecorder;
    try { mr = new MediaRecorder(stream, { mimeType: mime }); }
    catch (err) {
      try { mr = new MediaRecorder(stream); }
      catch (err2) {
        console.error('MediaRecorder construction failed', err2);
        stream.getTracks().forEach(t => t.stop());
        setStatus('Unable to start recording on this browser. Try Chrome/Edge.');
        setExporting(false);
        setMode('idle');
        return;
      }
    }

    mediaRecorderRef.current = mr;

    mr.ondataavailable = (e: BlobEvent) => { if (e.data && e.data.size > 0) recordedChunksRef.current.push(e.data); };
    mr.onerror = (ev) => { console.error('MediaRecorder error', ev); setStatus('Recording error occurred.'); };

    mr.onstop = () => {
      try {
        const blob = new Blob(recordedChunksRef.current, { type: mime });
        const url = URL.createObjectURL(blob);
        const a = document.createElement('a');
        a.href = url;
        a.download = `tts-export-${Date.now()}.webm`;
        document.body.appendChild(a);
        a.click();
        a.remove();
        setStatus('Export complete. File downloaded.');
      } catch (err) {
        console.error('Failed to finalize recording', err);
        setStatus('Failed to prepare the exported audio.');
      } finally {
        setExporting(false);
        setMode('idle');
        try { stream.getTracks().forEach(t => t.stop()); } catch (e) { /* ignore */ }
      }
    };

    try { mr.start(); }
    catch (err) {
      console.error('MediaRecorder.start failed', err);
      stream.getTracks().forEach(t => t.stop());
      setStatus('Failed to start recording. Ensure your browser supports recording and that tab audio is allowed.');
      setExporting(false);
      setMode('idle');
      return;
    }

    setStatus('Recording started — playing text now (do not switch tabs).');

    try {
      await sleep(250);
      await speak(false);
      await sleep(500);
    } catch (err) {
      console.error('Error while playing during export', err);
      setStatus('Playback failed during export. Recording will stop.');
    } finally {
      try { if (mediaRecorderRef.current && mediaRecorderRef.current.state !== 'inactive') mediaRecorderRef.current.stop(); } catch (e) { console.warn(e); }
    }
  }

  return (
    <div style={{ fontFamily: "Inter, ui-sans-serif, system-ui, -apple-system, 'Segoe UI', Roboto, 'Helvetica Neue', Arial", background: "linear-gradient(180deg,#071029 0%,#0f172a 60%)", color: "#e6eef8", minHeight: "100vh" }}>
      <div style={{ maxWidth: 1100, margin: "0 auto", padding: "48px 20px" }}>
        <header style={{ display: "flex", alignItems: "center", justifyContent: "space-between", gap: 20 }}>
          <div>
            <h1 style={{ color: "#fff", margin: 0, fontSize: 34 }}>{settings.title}</h1>
            <p style={{ color: "#9fb3d8", marginTop: 8 }}>{settings.tagline}</p>
          </div>
          <div style={{ textAlign: "right" }}>
            <div style={{ fontSize: 12, color: "#94a3b8" }}>Status:</div>
            <div style={{ fontWeight: 600 }}>{status || (supported ? 'Ready' : 'Browser missing features')}</div>
          </div>
        </header>

        <main style={{ marginTop: 28, display: "grid", gridTemplateColumns: "1fr 380px", gap: 24 }}>
          <section style={{ background: "#fff", color: '#0f172a', borderRadius: 12, padding: 18, boxShadow: "0 6px 30px rgba(2,6,23,0.6)" }}>
            <h2 style={{ marginTop: 0 }}>Text Editor</h2>
            <p style={{ color: "#334155", marginTop: 6 }}>Paste or type your text (books, scripts, long articles). The app will split large text into chunks and speak + export them seamlessly.</p>

            <div style={{ marginTop: 12 }}>
              <label style={{ display: "block", marginBottom: 6, color: "#475569" }}>Interpret as SSML</label>
              <input type="checkbox" checked={settings.ssml} onChange={(e)=>setSettings((s:any)=>({...s, ssml: e.target.checked}))} />
            </div>

            <textarea value={settings.text} onChange={(e)=>setSettings((s:any)=>({...s, text: e.target.value}))}
              style={{ width: "100%", minHeight: 300, marginTop: 12, padding: 12, borderRadius: 8, border: "1px solid #e2e8f0", fontSize: 15 }} />

            <div style={{ display: "flex", gap: 8, marginTop: 12, alignItems: "center" }}>
              <button onClick={()=>speak()} style={{ padding: "10px 16px", borderRadius: 10, background: "#7c3aed", color: "white", border: "none", cursor: "pointer" }}>▶ Play</button>
              <button onClick={()=>pause()} style={{ padding: "10px 16px", borderRadius: 10, background: "#f59e0b", color: "white", border: "none", cursor: "pointer" }}>⏸ Pause</button>
              <button onClick={()=>resume()} style={{ padding: "10px 16px", borderRadius: 10, background: "#10b981", color: "white", border: "none", cursor: "pointer" }}>▶ Resume</button>
              <button onClick={()=>stop()} style={{ padding: "10px 16px", borderRadius: 10, background: "#ef4444", color: "white", border: "none", cursor: "pointer" }}>⏹ Stop</button>
              <div style={{ flex: 1 }} />
              <button onClick={()=>exportAudio()} style={{ padding: "10px 14px", borderRadius: 10, background: exporting ? "#64748b" : "#0ea5e9", color: "white", border: "none", cursor: "pointer" }}>{exporting ? "Exporting..." : "⤓ Export Audio"}</button>
            </div>

            <div style={{ marginTop: 12, display: "flex", gap: 12, flexWrap: "wrap" }}>
              <div style={{ display: "flex", gap: 8, alignItems: "center" }}>
                <label style={{ color: "#475569" }}>Chunk size</label>
                <input type="number" value={settings.chunkSize} onChange={(e)=>setSettings((s:any)=>({...s, chunkSize: Math.max(1000, Number(e.target.value) || 5000)}))} style={{ width: 110, padding: 8, borderRadius: 8, border: "1px solid #e2e8f0" }} />
                <small style={{ color: "#94a3b8" }}>chars per chunk (default 5000)</small>
              </div>

              <div style={{ display: "flex", gap: 8, alignItems: "center" }}>
                <label style={{ color: "#475569" }}>Rate</label>
                <input type="range" min={0.5} max={2} step={0.05} value={settings.rate} onChange={(e)=>setSettings((s:any)=>({...s, rate: Number(e.target.value)}))} />
                <span style={{ color: "#475569" }}>{settings.rate.toFixed(2)}</span>
              </div>

              <div style={{ display: "flex", gap: 8, alignItems: "center" }}>
                <label style={{ color: "#475569" }}>Pitch</label>
                <input type="range" min={0} max={2} step={0.05} value={settings.pitch} onChange={(e)=>setSettings((s:any)=>({...s, pitch: Number(e.target.value)}))} />
                <span style={{ color: "#475569" }}>{settings.pitch.toFixed(2)}</span>
              </div>

              <div style={{ display: "flex", gap: 8, alignItems: "center" }}>
                <label style={{ color: "#475569" }}>Volume</label>
                <input type="range" min={0} max={1} step={0.01} value={settings.volume} onChange={(e)=>setSettings((s:any)=>({...s, volume: Number(e.target.value)}))} />
                <span style={{ color: "#475569" }}>{settings.volume.toFixed(2)}</span>
              </div>
            </div>

            <div style={{ marginTop: 14, color: "#475569", fontSize: 13 }}>
              <strong>Note:</strong> To export audio, your browser will ask you to share tab audio. Choose <em>This Tab</em> and enable audio. If your browser doesn't support tab audio capture, consider using a server-side TTS backend for exports.
            </div>
          </section>

          <aside style={{ background: "rgba(255,255,255,0.04)", borderRadius: 12, padding: 16, color: "#e6eef8" }}>
            <h3 style={{ marginTop: 0 }}>Voice Settings</h3>
            <div style={{ marginTop: 8 }}>
              <label style={{ display: "block", color: "#cbd5e1" }}>Language</label>
              <select value={settings.lang} onChange={(e)=>setSettings((s:any)=>({...s, lang: e.target.value}))} style={{ width: "100%", padding: 10, borderRadius: 8, marginTop: 8 }}>
                <option value="">(Auto from voice)</option>
                {Array.from(new Set(voices.map(v=>v.lang))).sort().map(l => <option key={l} value={l}>{l}</option>)}
              </select>

              <label style={{ display: "block", marginTop: 12, color: "#cbd5e1" }}>Voice</label>
              <select value={settings.voiceURI} onChange={(e)=>setSettings((s:any)=>({...s, voiceURI: e.target.value}))} style={{ width: "100%", padding: 10, borderRadius: 8, marginTop: 8 }}>
                {voices.map(v => <option key={v.voiceURI || v.name} value={v.voiceURI}>{v.name} — {v.lang}{v.default?" (default)":""}</option>)}
              </select>

              <div style={{ marginTop: 16 }}>
                <h4 style={{ margin: 0 }}>Quick Actions</h4>
                <div style={{ display: "flex", gap: 8, marginTop: 10 }}>
                  <button onClick={()=>setSettings((s:any)=>({...s, text: s.text + " <break time=\"500ms\"/>"}))} style={{ padding: "8px 12px", borderRadius: 8, border: "none", background: "#7c3aed", color: "white" }}>Insert Break</button>
                  <button onClick={()=>setSettings((s:any)=>({...s, text: s.text + "\n"}))} style={{ padding: "8px 12px", borderRadius: 8, border: "none", background: "#475569", color: "white" }}>New Line</button>
                  <button onClick={()=>setSettings((s:any)=>({...s, text: ""}))} style={{ padding: "8px 12px", borderRadius: 8, border: "none", background: "#ef4444", color: "white" }}>Clear</button>
                </div>
              </div>

              <div style={{ marginTop: 16, color: "#94a3b8", fontSize: 13 }}>
                <p style={{ margin: 0 }}>Browser capabilities vary. Use Chrome or Edge for best results. Large exports may take time depending on text length and system performance.</p>
              </div>
            </div>

            <div style={{ marginTop: 20 }}>
              <h4 style={{ margin: 0 }}>About</h4>
              <p style={{ color: "#94a3b8", fontSize: 13 }}>This open-source demo uses the Web Speech API for local synthesis and records tab audio to export a single merged audio file. For higher-fidelity exports or server-side control, integrate a backend TTS engine.</p>
            </div>
          </aside>
        </main>

        <footer style={{ marginTop: 36, color: "#94a3b8", textAlign: "center" }}>
          <div>© {new Date().getFullYear()} Open‑Source TTS • Built for unlimited-length speech (chunked & merged)</div>
        </footer>
      </div>
    </div>
  );
}
